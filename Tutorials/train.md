## Training a foundational instruction representation model

1. Setup the environment and build data processing programs.

```
cd <path to PerfVec>
source setup.sh
cd DP; make in; make out; cd ..
```

2. Generate traces by simulating a set of programs on a set of
microarchitectures using gem5.
See [gem5.md](gem5.md) for how to use gem5 for trace generation.

   [CAUTION] This script: [Tutorials/run_gem5_multiple.py](../Tutorials/run_gem5_multiple.py) is additionally provided for generating multiple traces at once. Should use with caution. This script could generate a large amount of files and consume large storage space. All generated traces with serial number will be placed in ```out_dir```.

   Example usage:
   ```
   cd <path to PerfVec>
   python ./Tutorials/run_gem5_multiple.py --num_samples=77 --out_dir=<an existing output directory>
   ```

   

4. Generate the PerfVec model input from gem5 instruction execution traces.
To generate the input of a specific program, find a trace of it, and perform
the following commands.

```
mv <path to trace>/sq.trace.txt <path to trace>/trace.sq.txt
python -m DP.trace2nmmap <path to trace>/trace.txt
```

This command produces a file named `<path to trace>/trace.in.nmmap` and outputs
the number of instructions it includes.

4. Generate the training target from gem5 instruction execution traces.
We combine the traces of a certain program executed on all microarchitectures
into a single output file.

```
./DP/buildComOut <trace1> <trace2> ... <tracen>
python -m DP.inst2mmap -t -l=<trace length> <output file of last command>
```

With proper modification, [DP/combine_out.py](../DP/combine_out.py) can be used
to simplify the first command.

5. Create a config file for the generated data.
An example can be seen in [CFG/com_0522.py](../CFG/com_0522.py).
The following information is needed in the config file.
    * List the name, input size (generated by Step 3), and output size (generated by Step 4)
    for each program in `datasets`.
    * Modify `data_set_idx` to be the number of programs.
    * Calculate the total number of entries (i.e., sum output sizes), and then modify
    `testbatchnum`, `testbatchsize`, `validbatchnum`, and `validbatchsize` to
    specify the testing and validation portions.
    * Modify `cfg_num` to be the number of microarchitectures.

6. Train a PerfVec foundation model.
See [ML/models](../ML/models) for various model options, or implement your own.

```
python -m ML.train --cfg=<config name> --train-size=<# instructions for training> \\
  --epochs=<# epochs> --batch-size=<batch size> --sbatch <model instantiation>
```
